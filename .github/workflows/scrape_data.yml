name: Daily Data Scrape and Process

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '0 8 * * 1-5' # Runs at 8 AM UTC on weekdays

jobs:
  scrape-and-process:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      - name: Install Google Chrome Stable
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add - 
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Modify scraper.py to run headless for automation
        run: |
          # This command inserts the --headless argument needed for the server environment
          sed -i '/options.add_argument("start-maximized")/a \    options.add_argument("--headless")' scraper.py

      - name: Run Scraper and Processor
        id: run_scripts # Give this step an ID to check its outcome
        run: |
          python scraper.py
          python data_processor.py

      - name: Commit and push data files
        # This step will only run if the previous step was successful
        # AND if the CSV files were actually created.
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions-bot@github.com"
          # Check if the output file exists before trying to add it
          if [ -f "processed_job_data.csv" ]; then
            git add raw_job_data.csv processed_job_data.csv
            # Commit only if there are changes
            if git diff --staged --quiet; then
              echo "No changes in data to commit."
            else
              git commit -m "Update: Daily job data refresh"
              git push
            fi
          else
            echo "processed_job_data.csv not found. Skipping commit. Scraper likely failed."
            # We will now explicitly fail the workflow to make the error clear
            exit 1
          fi